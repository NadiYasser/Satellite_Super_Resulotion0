{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f079f3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "device : cuda\n",
      "\n",
      " DATA LOADED:\n",
      "  Train: 64800 samples\n",
      "  Val:   8100 samples\n",
      "  Test:  8100 samples\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os \n",
    "os.chdir(\"/home/jadli/Bureau/BDAI2/Satellite_Super_Resulotion0\")\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from importlib import reload\n",
    "import src.utils.config\n",
    "reload(src.utils.config)\n",
    "from src.utils.config import CONFIG\n",
    "\n",
    "from src.utils.data_loader import create_loaders\n",
    "from src.models.models_architecture import EDSR       \n",
    "from src.utils.helper_functions import train_sr, val_sr, plot_sr_progress\n",
    "\n",
    "import json\n",
    "\n",
    "best_model_path = CONFIG[\"model\"][\"best_EDSR_path\"]\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"device : {device}\")\n",
    "\n",
    "# CONFIG FROM YAML \n",
    "data_root      = CONFIG[\"paths\"][\"output_root\"]\n",
    "batch_size     = CONFIG[\"training\"][\"batch_size\"]\n",
    "num_workers    = CONFIG[\"training\"][\"num_workers\"]\n",
    "use_aug        = CONFIG[\"training\"].get(\"use_augmentation\", True)\n",
    "\n",
    "# HYPERPARAMS FROM CONFIG \n",
    "lr              = 0.0005 #CONFIG[\"training\"][\"lr\"]\n",
    "weight_decay    = CONFIG[\"training\"][\"weight_decay\"]\n",
    "num_epochs      = 5 #CONFIG[\"training\"][\"epochs\"]\n",
    "step_size       = 1 #CONFIG[\"training\"][\"scheduler_step_size\"]\n",
    "gamma           = 0.5 #CONFIG[\"training\"][\"scheduler_gamma\"]\n",
    "\n",
    "\n",
    "# LOAD DATA \n",
    "\n",
    "train_loader, val_loader, test_loader = create_loaders(\n",
    "    root=data_root,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    use_augmentation=use_aug\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9360a44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: src/models/checkpoints/EDSR/best_EDSR.pth\n",
      " Resuming training from epoch 14 | Best PSNR = 27.07\n",
      "14\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_93430/3397045918.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(best_model_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = EDSR().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "\n",
    "best_psnr = 0.0\n",
    "best_model_path = CONFIG[\"model\"][\"best_EDSR_path\"]\n",
    "history_path = CONFIG[\"model\"][\"history_path\"]\n",
    "os.makedirs(os.path.dirname(best_model_path), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(history_path), exist_ok=True)\n",
    "\n",
    "\n",
    "# LOAD CHECKPOINT IF EXISTS\n",
    "start_epoch = 0\n",
    "\n",
    "if os.path.exists(best_model_path):\n",
    "    print(\"Loading checkpoint:\", best_model_path)\n",
    "    checkpoint = torch.load(best_model_path, map_location=device)\n",
    "\n",
    "    if \"model\" in checkpoint:\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "        scheduler.load_state_dict(checkpoint[\"scheduler\"])\n",
    "        best_psnr = checkpoint[\"best_psnr\"]\n",
    "        start_epoch = checkpoint[\"epoch\"] + 1\n",
    "        print(f\" Resuming training from epoch {start_epoch} | Best PSNR = {best_psnr:.2f}\")\n",
    "    else:\n",
    "        print(\" Old checkpoint without optimizer/scheduler. Loading model only.\")\n",
    "        model.load_state_dict(checkpoint)\n",
    "else:\n",
    "    print(\" Training from scratch\")\n",
    "\n",
    "\n",
    "# LOAD TRAINING HISTORY\n",
    "train_losses, val_losses = [], []\n",
    "train_psnrs, val_psnrs = [], []\n",
    "\n",
    "if os.path.exists(history_path):\n",
    "    print(\" Loading training history...\")\n",
    "    with open(history_path, \"r\") as f:\n",
    "        history = json.load(f)\n",
    "\n",
    "    train_losses = history[\"train_losses\"]\n",
    "    val_losses   = history[\"val_losses\"]\n",
    "    train_psnrs  = history[\"train_psnrs\"]\n",
    "    val_psnrs    = history[\"val_psnrs\"]\n",
    "else:\n",
    "    print(\"No previous training history found.\")\n",
    "\n",
    "\n",
    "# TRAIN LOOP\n",
    "num_epochs += start_epoch  \n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    # TRAIN\n",
    "    train_loss, train_psnr = train_sr(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        loss_fn=criterion,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        scale_factor=4,\n",
    "        model_requires_upscale=False,\n",
    "        scheduler=scheduler\n",
    "    )\n",
    "\n",
    "    # VALIDATION\n",
    "    val_loss, val_psnr = val_sr(\n",
    "        model=model,\n",
    "        val_loader=val_loader,\n",
    "        loss_fn=criterion,\n",
    "        device=device,\n",
    "        scale_factor=4,\n",
    "        model_requires_upscale=False\n",
    "    )\n",
    "\n",
    "    # SAVE BEST MODEL\n",
    "    if val_psnr > best_psnr:\n",
    "        best_psnr = val_psnr\n",
    "        torch.save({\n",
    "            \"model\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"scheduler\": scheduler.state_dict(),\n",
    "            \"epoch\": epoch,\n",
    "            \"best_psnr\": best_psnr,\n",
    "        }, best_model_path)\n",
    "\n",
    "        print(f\" New BEST model saved at epoch {epoch+1} with PSNR = {best_psnr:.2f}\")\n",
    "\n",
    "    # APPEND HISTORY\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_psnrs.append(train_psnr)\n",
    "    val_psnrs.append(val_psnr)\n",
    "\n",
    "    # SAVE HISTORY\n",
    "    history = {\n",
    "        \"train_losses\": train_losses,\n",
    "        \"val_losses\": val_losses,\n",
    "        \"train_psnrs\": train_psnrs,\n",
    "        \"val_psnrs\": val_psnrs\n",
    "    }\n",
    "    with open(history_path, \"w\") as f:\n",
    "        json.dump(history, f)\n",
    "\n",
    "    print(f\"Train loss: {train_loss:.6f} | Train PSNR: {train_psnr:.2f} dB\")\n",
    "    print(f\"Val   loss: {val_loss:.6f} | Val   PSNR: {val_psnr:.2f} dB\")\n",
    "    print(f\"-> LR: {optimizer.param_groups[0]['lr']:.8f}\")\n",
    "\n",
    "# FINAL PLOT\n",
    "plot_sr_progress(train_losses, val_losses, train_psnrs, val_psnrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656f22b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EDSR().to(device)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "\n",
    "best_psnr = 0.0\n",
    "best_model_path = CONFIG[\"model\"][\"best_EDSR_path\"]\n",
    "history_path = CONFIG[\"model\"][\"history_path\"]\n",
    "os.makedirs(os.path.dirname(best_model_path), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(history_path), exist_ok=True)\n",
    "\n",
    "\n",
    "# LOAD CHECKPOINT IF EXISTS\n",
    "start_epoch = 0\n",
    "\n",
    "if os.path.exists(best_model_path):\n",
    "    print(\"Loading checkpoint:\", best_model_path)\n",
    "    checkpoint = torch.load(best_model_path, map_location=device)\n",
    "\n",
    "    if \"model\" in checkpoint:\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "        scheduler.load_state_dict(checkpoint[\"scheduler\"])\n",
    "        best_psnr = checkpoint[\"best_psnr\"]\n",
    "        start_epoch = checkpoint[\"epoch\"] + 1\n",
    "        print(f\" Resuming training from epoch {start_epoch} | Best PSNR = {best_psnr:.2f}\")\n",
    "    else:\n",
    "        print(\" Old checkpoint without optimizer/scheduler. Loading model only.\")\n",
    "        model.load_state_dict(checkpoint)\n",
    "else:\n",
    "    print(\" Training from scratch\")\n",
    "\n",
    "\n",
    "# LOAD TRAINING HISTORY\n",
    "train_losses, val_losses = [], []\n",
    "train_psnrs, val_psnrs = [], []\n",
    "\n",
    "if os.path.exists(history_path):\n",
    "    print(\" Loading training history...\")\n",
    "    with open(history_path, \"r\") as f:\n",
    "        history = json.load(f)\n",
    "\n",
    "    train_losses = history[\"train_losses\"]\n",
    "    val_losses   = history[\"val_losses\"]\n",
    "    train_psnrs  = history[\"train_psnrs\"]\n",
    "    val_psnrs    = history[\"val_psnrs\"]\n",
    "else:\n",
    "    print(\"No previous training history found.\")\n",
    "\n",
    "\n",
    "# TRAIN LOOP\n",
    "num_epochs += start_epoch  \n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    # TRAIN\n",
    "    train_loss, train_psnr = train_sr(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        loss_fn=criterion,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        scale_factor=4,\n",
    "        model_requires_upscale=False,\n",
    "        scheduler=scheduler\n",
    "    )\n",
    "\n",
    "    # VALIDATION\n",
    "    val_loss, val_psnr = val_sr(\n",
    "        model=model,\n",
    "        val_loader=val_loader,\n",
    "        loss_fn=criterion,\n",
    "        device=device,\n",
    "        scale_factor=4,\n",
    "        model_requires_upscale=False\n",
    "    )\n",
    "\n",
    "    # SAVE BEST MODEL\n",
    "    if val_psnr > best_psnr:\n",
    "        best_psnr = val_psnr\n",
    "        torch.save({\n",
    "            \"model\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"scheduler\": scheduler.state_dict(),\n",
    "            \"epoch\": epoch,\n",
    "            \"best_psnr\": best_psnr,\n",
    "        }, best_model_path)\n",
    "\n",
    "        print(f\" New BEST model saved at epoch {epoch+1} with PSNR = {best_psnr:.2f}\")\n",
    "\n",
    "    # APPEND HISTORY\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_psnrs.append(train_psnr)\n",
    "    val_psnrs.append(val_psnr)\n",
    "\n",
    "    # SAVE HISTORY\n",
    "    history = {\n",
    "        \"train_losses\": train_losses,\n",
    "        \"val_losses\": val_losses,\n",
    "        \"train_psnrs\": train_psnrs,\n",
    "        \"val_psnrs\": val_psnrs\n",
    "    }\n",
    "    with open(history_path, \"w\") as f:\n",
    "        json.dump(history, f)\n",
    "\n",
    "    print(f\"Train loss: {train_loss:.6f} | Train PSNR: {train_psnr:.2f} dB\")\n",
    "    print(f\"Val   loss: {val_loss:.6f} | Val   PSNR: {val_psnr:.2f} dB\")\n",
    "    print(f\"-> LR: {optimizer.param_groups[0]['lr']:.8f}\")\n",
    "\n",
    "# FINAL PLOT\n",
    "plot_sr_progress(train_losses, val_losses, train_psnrs, val_psnrs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BDAI2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
