{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f7fecdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device : cuda\n",
      "\n",
      " DATA LOADED:\n",
      "  Train: 152352 samples\n",
      "  Val:   19044 samples\n",
      "  Test:  19044 samples\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os \n",
    "os.chdir(\"/home/jadli/Bureau/BDAI2/Satellite_Super_Resulotion0\")\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from importlib import reload    \n",
    "\n",
    "from src.utils.config import CONFIG\n",
    "\n",
    "from src.utils.data_loader import create_loaders\n",
    "from notebooks.yasser.custom_model import Custom_model     \n",
    "from src.utils.train_model_sr import train_model_sr\n",
    "import json\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"device : {device}\")\n",
    "\n",
    "# CONFIG FROM YAML \n",
    "data_root      = CONFIG[\"paths\"][\"output_root\"]\n",
    "batch_size     = 64 #CONFIG[\"training\"][\"batch_size\"]\n",
    "num_workers    = CONFIG[\"training\"][\"num_workers\"]\n",
    "use_aug        = CONFIG[\"training\"].get(\"use_augmentation\", True)\n",
    "\n",
    "# HYPERPARAMS FROM CONFIG \n",
    "lr              = 0.0001 #CONFIG[\"training\"][\"lr\"]\n",
    "weight_decay    = 0\n",
    "num_epochs      = 50 #CONFIG[\"training\"][\"epochs\"]\n",
    "step_size       = 30 #CONFIG[\"training\"][\"scheduler_step_size\"]\n",
    "gamma           = 0.5 #CONFIG[\"training\"][\"scheduler_gamma\"]\n",
    "\n",
    "\n",
    "# LOAD DATA \n",
    "\n",
    "train_loader, val_loader, test_loader = create_loaders(\n",
    "    root=data_root,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    use_augmentation=use_aug\n",
    ")\n",
    "\n",
    "model_large = Custom_model(n_HF_blocks=8,n_MS_blocks=2,n_LF_blocks=16).to(device)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model_large.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 30, 45], gamma=0.5)\n",
    "\n",
    "best_model_path = CONFIG[\"model\"][\"best_custom_large_path\"]\n",
    "last_model_path = CONFIG[\"model\"][\"last_custom_large_path\"]\n",
    "history_path = CONFIG[\"history\"][\"custom_large_history_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf3584a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training custom_model_large from scratch\n",
      "No previous training history found.\n",
      "\n",
      " [custom_model_large] Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/2381 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 1 with PSNR = 27.12\n",
      "Train loss: 0.036919 | Train PSNR: 24.69 dB\n",
      "Val   loss: 0.030279 | Val   PSNR: 27.12 dB\n",
      "-> LR: 0.00010000\n",
      "\n",
      " [custom_model_large] Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 2 with PSNR = 27.34\n",
      "Train loss: 0.033411 | Train PSNR: 25.16 dB\n",
      "Val   loss: 0.029330 | Val   PSNR: 27.34 dB\n",
      "-> LR: 0.00010000\n",
      "\n",
      " [custom_model_large] Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 3 with PSNR = 27.45\n",
      "Train loss: 0.032825 | Train PSNR: 25.25 dB\n",
      "Val   loss: 0.028817 | Val   PSNR: 27.45 dB\n",
      "-> LR: 0.00010000\n",
      "\n",
      " [custom_model_large] Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 4 with PSNR = 27.48\n",
      "Train loss: 0.032490 | Train PSNR: 25.31 dB\n",
      "Val   loss: 0.028689 | Val   PSNR: 27.48 dB\n",
      "-> LR: 0.00010000\n",
      "\n",
      " [custom_model_large] Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 5 with PSNR = 27.56\n",
      "Train loss: 0.032245 | Train PSNR: 25.36 dB\n",
      "Val   loss: 0.028367 | Val   PSNR: 27.56 dB\n",
      "-> LR: 0.00010000\n",
      "\n",
      " [custom_model_large] Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 6 with PSNR = 27.59\n",
      "Train loss: 0.032028 | Train PSNR: 25.41 dB\n",
      "Val   loss: 0.028232 | Val   PSNR: 27.59 dB\n",
      "-> LR: 0.00010000\n",
      "\n",
      " [custom_model_large] Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 7 with PSNR = 27.65\n",
      "Train loss: 0.031804 | Train PSNR: 25.49 dB\n",
      "Val   loss: 0.027994 | Val   PSNR: 27.65 dB\n",
      "-> LR: 0.00010000\n",
      "\n",
      " [custom_model_large] Epoch 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 8 with PSNR = 27.68\n",
      "Train loss: 0.031611 | Train PSNR: 25.55 dB\n",
      "Val   loss: 0.027905 | Val   PSNR: 27.68 dB\n",
      "-> LR: 0.00010000\n",
      "\n",
      " [custom_model_large] Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 9 with PSNR = 27.71\n",
      "Train loss: 0.031455 | Train PSNR: 25.59 dB\n",
      "Val   loss: 0.027786 | Val   PSNR: 27.71 dB\n",
      "-> LR: 0.00010000\n",
      "\n",
      " [custom_model_large] Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 10 with PSNR = 27.74\n",
      "Train loss: 0.031320 | Train PSNR: 25.62 dB\n",
      "Val   loss: 0.027670 | Val   PSNR: 27.74 dB\n",
      "-> LR: 0.00010000\n",
      "\n",
      " [custom_model_large] Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 11 with PSNR = 27.77\n",
      "Train loss: 0.031198 | Train PSNR: 25.65 dB\n",
      "Val   loss: 0.027554 | Val   PSNR: 27.77 dB\n",
      "-> LR: 0.00010000\n",
      "\n",
      " [custom_model_large] Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 12 with PSNR = 27.80\n",
      "Train loss: 0.031090 | Train PSNR: 25.68 dB\n",
      "Val   loss: 0.027439 | Val   PSNR: 27.80 dB\n",
      "-> LR: 0.00010000\n",
      "\n",
      " [custom_model_large] Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 13 with PSNR = 27.83\n",
      "Train loss: 0.030988 | Train PSNR: 25.70 dB\n",
      "Val   loss: 0.027350 | Val   PSNR: 27.83 dB\n",
      "-> LR: 0.00010000\n",
      "\n",
      " [custom_model_large] Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 14 with PSNR = 27.83\n",
      "Train loss: 0.030897 | Train PSNR: 25.72 dB\n",
      "Val   loss: 0.027337 | Val   PSNR: 27.83 dB\n",
      "-> LR: 0.00010000\n",
      "\n",
      " [custom_model_large] Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 15 with PSNR = 27.86\n",
      "Train loss: 0.030807 | Train PSNR: 25.74 dB\n",
      "Val   loss: 0.027228 | Val   PSNR: 27.86 dB\n",
      "-> LR: 0.00005000\n",
      "\n",
      " [custom_model_large] Epoch 16/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 16 with PSNR = 27.88\n",
      "Train loss: 0.030691 | Train PSNR: 25.77 dB\n",
      "Val   loss: 0.027130 | Val   PSNR: 27.88 dB\n",
      "-> LR: 0.00005000\n",
      "\n",
      " [custom_model_large] Epoch 17/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 17 with PSNR = 27.90\n",
      "Train loss: 0.030645 | Train PSNR: 25.78 dB\n",
      "Val   loss: 0.027052 | Val   PSNR: 27.90 dB\n",
      "-> LR: 0.00005000\n",
      "\n",
      " [custom_model_large] Epoch 18/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 18 with PSNR = 27.92\n",
      "Train loss: 0.030603 | Train PSNR: 25.79 dB\n",
      "Val   loss: 0.027009 | Val   PSNR: 27.92 dB\n",
      "-> LR: 0.00005000\n",
      "\n",
      " [custom_model_large] Epoch 19/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 19 with PSNR = 27.93\n",
      "Train loss: 0.030563 | Train PSNR: 25.80 dB\n",
      "Val   loss: 0.026981 | Val   PSNR: 27.93 dB\n",
      "-> LR: 0.00005000\n",
      "\n",
      " [custom_model_large] Epoch 20/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 20 with PSNR = 27.93\n",
      "Train loss: 0.030523 | Train PSNR: 25.80 dB\n",
      "Val   loss: 0.026954 | Val   PSNR: 27.93 dB\n",
      "-> LR: 0.00005000\n",
      "\n",
      " [custom_model_large] Epoch 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 21 with PSNR = 27.94\n",
      "Train loss: 0.030487 | Train PSNR: 25.81 dB\n",
      "Val   loss: 0.026938 | Val   PSNR: 27.94 dB\n",
      "-> LR: 0.00005000\n",
      "\n",
      " [custom_model_large] Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 22 with PSNR = 27.96\n",
      "Train loss: 0.030451 | Train PSNR: 25.82 dB\n",
      "Val   loss: 0.026882 | Val   PSNR: 27.96 dB\n",
      "-> LR: 0.00005000\n",
      "\n",
      " [custom_model_large] Epoch 23/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 23 with PSNR = 27.97\n",
      "Train loss: 0.030418 | Train PSNR: 25.83 dB\n",
      "Val   loss: 0.026836 | Val   PSNR: 27.97 dB\n",
      "-> LR: 0.00005000\n",
      "\n",
      " [custom_model_large] Epoch 24/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 24 with PSNR = 27.98\n",
      "Train loss: 0.030387 | Train PSNR: 25.83 dB\n",
      "Val   loss: 0.026832 | Val   PSNR: 27.98 dB\n",
      "-> LR: 0.00005000\n",
      "\n",
      " [custom_model_large] Epoch 25/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New BEST model saved at epoch 25 with PSNR = 27.98\n",
      "Train loss: 0.030355 | Train PSNR: 25.84 dB\n",
      "Val   loss: 0.026815 | Val   PSNR: 27.98 dB\n",
      "-> LR: 0.00005000\n",
      "\n",
      " [custom_model_large] Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.030324 | Train PSNR: 25.85 dB\n",
      "Val   loss: 0.026792 | Val   PSNR: 27.97 dB\n",
      "-> LR: 0.00005000\n",
      "\n",
      " [custom_model_large] Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_model_sr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_large\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcustom_model_large\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscale_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_requires_upscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbest_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlast_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscratch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_amp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m  \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Bureau/BDAI2/Satellite_Super_Resulotion0/src/utils/train_model_sr.py:105\u001b[0m, in \u001b[0;36mtrain_model_sr\u001b[0;34m(model, model_name, train_loader, val_loader, device, criterion, optimizer, scheduler, num_epochs, scale_factor, model_requires_upscale, best_model_path, last_model_path, history_path, mode, use_amp, scaler)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# TRAIN\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_amp:\n\u001b[0;32m--> 105\u001b[0m     train_loss, train_psnr, scaler \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_sr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_requires_upscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_amp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaler\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     train_loss, train_psnr \u001b[38;5;241m=\u001b[39m train_sr(\n\u001b[1;32m    119\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    120\u001b[0m         train_loader\u001b[38;5;241m=\u001b[39mtrain_loader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m         use_amp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     )\n",
      "File \u001b[0;32m~/Bureau/BDAI2/Satellite_Super_Resulotion0/src/utils/helper_functions.py:56\u001b[0m, in \u001b[0;36mtrain_sr\u001b[0;34m(model, train_loader, loss_fn, optimizer, device, scale_factor, model_requires_upscale, scheduler, use_amp, scaler)\u001b[0m\n\u001b[1;32m     54\u001b[0m     sr \u001b[38;5;241m=\u001b[39m model(lr_in)\n\u001b[1;32m     55\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(sr, hr)\n\u001b[0;32m---> 56\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[1;32m     58\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[0;32m~/miniconda3/envs/BDAI2/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/BDAI2/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/BDAI2/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs=30\n",
    "train_model_sr(\n",
    "    model=model_large,\n",
    "    model_name=\"custom_model_large\",\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    scale_factor=4,\n",
    "    model_requires_upscale=False,\n",
    "    best_model_path=best_model_path,\n",
    "    last_model_path=last_model_path,\n",
    "    mode=\"scratch\",\n",
    "    history_path=history_path,\n",
    "    use_amp=True  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b1f3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BDAI2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
